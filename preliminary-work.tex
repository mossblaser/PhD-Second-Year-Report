\chapter{Preliminary work}
	\label{sec:preliminary-work}
	
	% TODO: Add more linking together perhaps?
	
	The work outlined in this chapter initially concentrates on developing a
	fuller understanding of the characteristics of the interconnection networks
	used in SpiNNaker. This work has developed into the foundations for new
	extensions to the SpiNNaker network which will form the main contributions of
	this project.
	
	The chapter begins with the development of an efficient wiring scheme for
	large SpiNNaker systems which accounts for the properties of HSS interconnect
	technology. This is followed by a discussion of an extension to the network
	which exploits this wiring scheme to transform the network into a small-world
	network with improved latency using a small number of additional cables.  As
	part of an effort to validate these changes, a model of SpiNNaker's
	interconnection network has been built. A brief description of this work is
	included along with details of collaborative work to develop new modelling
	techniques.  The chapter concludes with an overview of extensions being made
	to the existing HSS board-to-board links within SpiNNaker which will form the
	foundations of an implementation of small-world networking.
	
	\section{SpiNNaker machine wiring}
		
		% Constraint of electrical high-speed serial is that long wires are not
		% allowed. For tori, this is a problem due to wrap-around.
		
		Electrical HSS links impose restrictions on the maximum length of cables. In
		the case of SpiNNaker's board-to-board links, which follow the S-ATA
		physical connection standard, cable lengths are limited to one metre for
		most applications \cite{sata3spec}. Due to SpiNNaker's torus topology, this
		restriction necessitates a non-trivial wiring scheme as described in this
		section.
		
		\begin{figure}
			\center
			\input{|"python2 figures/boardsLogical.py"}
			\caption[Logical arrangement of boards in a 48 board SpiNNaker
			system.]{Logical arrangement of boards in a 48 board SpiNNaker system.
			Touching boards are connected. Coloured lines represent long connections
			travelling {\color{red}North/South},
			{\color{green}North-East/South-West} and {\color{blue}East/West}.}
			\label{fig:boardsLogical}
		\end{figure}
		
		Figure \ref{fig:boardsLogical} shows the logical connectivity between boards
		in a small SpiNNaker system containing 48 boards (represented as hexagons).
		Touching edges represent a connection between two boards. Lines show the
		connectivity between boards on opposite sides of the system. While the
		majority of wires are very short (i.e. connecting two boards which are
		side-by-side), some wires must cross the entire system's length. If
		SpiNNaker boards are arranged na\"ively to match their logical layout, for
		the largest planned SpiNNaker machine, spanning ten server-room cabinets,
		wires over six metres long would be needed, far beyond the one metre
		technology limit.
		
		The principles of the machine's construction described by by Davidson
		\cite{davidsonWiring} and Furber \cite{furber13email} were used as the basis
		for a tool, SpiNNer, used to model and experiment with possible physical
		arrangements of SpiNNaker boards \footnote{The SpiNNer tool was also used to
		generate many of the figures in this section.}. The development and use of
		this tool has led to the design of practical wiring schemes for SpiNNaker
		systems ranging in size from three boards to ten cabinets (1,200 boards).
		This section describes the principle by which these schemes are produced.
		
		\subsection{Reducing wiring length}
			
			\begin{figure}
				\begin{subfigure}[b]{\textwidth}
					\center
					\input{figures/ringLong}
					\caption{A ring network}
					\label{fig:ringLong}
				\end{subfigure}
				
				\vspace{2ex}
				
				\begin{subfigure}[b]{\textwidth}
					\center
					\input{figures/ringFolded}
					\caption{Folded in half}
					\label{fig:ringFolded}
				\end{subfigure}
				
				\vspace{2ex}
				
				\begin{subfigure}[b]{\textwidth}
					\center
					\input{figures/ringInterleaved}
					\caption{Interleaved}
					\label{fig:ringInterleaved}
				\end{subfigure}
				
				\caption[Folding a ring network.]{The process of folding a ring network
				to reduce the maximum wire length.}
				\label{fig:folding}
			\end{figure}
			
			\begin{figure}
				\center
				\begin{subfigure}[b]{\textwidth}
					\center
					\input{|"python2 figures/boardsFoldedShift.py"}
					\caption{Shift boards on the left to the right to form a rectangle.}
					\label{fig:boardsFoldedShift}
				\end{subfigure}
				
				\vspace{2ex}
				
				\begin{subfigure}[b]{\textwidth}
					\center
					\input{|"python2 figures/boardsFoldedSpaced.py"}
					\caption{Fold along the gaps in this figure. (Wires omitted for
					clarity.)}
					\label{fig:boardsFoldedSpaced}
				\end{subfigure}
				
				\vspace{2ex}
				
				\begin{subfigure}[b]{\textwidth}
					\center
					\input{|"python2 figures/boardsFoldedInterleaved.py"}
					\caption{The (more complex) wiring after folding. (Shown here with
					squares since hexagons do not visually fit together after folding and
					interleaving.)}
					\label{fig:boardsFoldedInterleaved}
				\end{subfigure}
				
				\caption[Folding SpiNNaker.]{The process of folding SpiNNaker. Coloured
				lines represent wires travelling {\color{red}North/South},
				{\color{green}North-East/South-West} and {\color{blue}East/West}.}
				\label{fig:boardsFolded}
			\end{figure}
			
			Long wires can be avoided in toroidal networks by `folding'
			\cite{dally04}.  An example of this process is shown for a simple
			ring-network (a 1-dimensional toroid) in figure \ref{fig:folding}. This
			process is generalised to SpiNNaker's boards as shown in figure
			\ref{fig:boardsFolded}. The first step (figure
			\ref{fig:boardsFoldedShift}) transforms the rhombus-like arrangement of
			boards into a rectangle which is more easily folded.
			
			In the next step, the design is folded into four parts along the Y-axis
			and into two along the X-axis (figure \ref{fig:boardsFoldedSpaced}). It is
			necessary to fold along the Y-axis into four to eliminate the long,
			diagonal connections. Folding in two would not bring these points any
			closer while folding into four brings them next to each other. For
			example, the wire travelling from the bottom left board to the top-middle
			board after folding in two would now have to cross from one end of the
			system to the other, an even longer distance than it had to before. By
			folding in this way the maximum wire length is reduced producing the
			wiring shown in figure \ref{fig:boardsFoldedInterleaved}.
			
			\label{sec:mapping-spinnaker-to-cabinets}
			
			\begin{figure}
				\center
				\includegraphics[width=\textwidth]{figures/spinnaker106}
				\caption[SpiNNaker machine mapped into cabinets and racks.]{The largest
				planned SpiNNaker machine with 1,200 boards and 1,036,800 cores mapped
				into 10 cabinets of 5 racks each.  Coloured lines represent wires
				connecting {\color{red}North/South},
				{\color{green}North-East/South-West} and {\color{blue}East/West} links.}
				\label{fig:spinnaker106}
			\end{figure}
			
			The final step is to map the boards into their real-world physical
			positions. The largest SpiNNaker system will be installed into a series of
			cabinets, each containing a number of racks into which the boards are
			slotted and wired together. Figure \ref{fig:spinnaker106} shows the
			proposed rack placement scheme for the largest planned SpiNNaker system of
			1,200 boards. Even though the system is physically around six metres long,
			the longest wire will be less than one metre in length and thus within the
			S-ATA specification.
		
		\subsection{Future Work}
			
			% The tool has been successfuly used to
			% assemble machines (pictures!) and provide orders for cabling for the
			% next machines. Next stage will involve extending this to interactively
			% guiding larger builds and 
			
			\begin{figure}
				\begin{subfigure}{0.49\textwidth}
					\includegraphics[width=\textwidth]{figures/rack-front.jpg}
					
					\caption{Front}
					\label{fig:rack-front}
				\end{subfigure}
				\begin{subfigure}{0.49\textwidth}
					\includegraphics[width=\textwidth]{figures/rack-back.jpg}
					
					\caption{Back}
					\label{fig:rack-back}
				\end{subfigure}
				
				\caption{Wiring for a prototype `desk-side' SpiNNaker system.}
				\label{fig:rack}
			\end{figure}
			
			Wiring plans produced by SpiNNer have already successfully been used in
			the construction of small `desk-side' 24-board SpiNNaker systems
			containing 20,736 cores (figure \ref{fig:rack}). The tool is also being
			used in the ongoing construction of larger SpiNNaker machines. Due to the
			larger size of these machines, the tool must be extended to break down the
			wiring plans into multiple diagrams to aid usability.
	
	
	\section{Small-world networks}
		
		% Small-world networks are: ... Allow lots of short paths, this means low
		% latency, low power and less contention. We describe ways of augmenting the
		% SpiNNaker network, making use of spare connections and resource for
		% board-to-board links while taking advantage of the physical arrangement
		% described in the previous section.
		
		Small-world networks are graphs with a very large number of nodes but,
		within which, the shortest path between any pair of nodes is small.
		Additionally, each node in the graph features only a relatively small number
		of connections. They also contain `clusters' of well connected nodes, in
		contrast with random graphs (which may also fulfil the first criterion).
		
		Small-world networks are often found in nature, perhaps most famously in
		social networks. In this context, the phenomenon was first observed in 1929
		by Hungarian author Frigyes Karinthy \cite{karinthy29} and the idea has
		become popularly known as the theory of `six degrees of separation'. The
		theory states that for any two people on earth, chosen at random, there is a
		chain of at most 6 acquaintances which connects them.
		
		This property of maintaining low maximum shortest-path length while still
		remaining locally well connected is desirable for certain computational
		problems. In neural simulations, most communication is local with just a few
		longer connections. The clustering property of small-world networks means
		these local connections can be well catered for while the low maximum
		shortest-path length means longer connections are still quick for very large
		models.
		
		In this section a method for constructing small-world networks within
		SpiNNaker's board-to-board links is introduced which does not require
		physically long connections while still exhibiting significant reductions in
		network latency.
		
		\subsection{Constructing small-world networks}
			
			% Add random links and lo-and-behold, smallworldness!
			
			Watts and Strogatz have proposed an algorithm for randomly constructing
			networks with small-world properties \cite{watts98}. The algorithm begins
			by creating a ring-like network with each node connecting to a fixed
			number of its neighbours (figure \ref{fig:ringNetworkB0}). In the next
			step, with a probability of $\beta$, each edge may be replaced by a random
			connection.  For $0 < \beta < 1$, the networks produced exhibit varying
			degrees of the small-world properties (figure \ref{fig:ringNetworkB02}).
			Finally, in the extreme case where $\beta=1$, the network devolves into a
			random network (figure \ref{fig:ringNetworkB1}).
			
			\begin{figure}
				\center
				\begin{subfigure}[t]{0.3\textwidth}
					\center
					\input{figures/ringNetwork}
					\caption{Ring ($\beta = 0.0$)}
					\label{fig:ringNetworkB0}
				\end{subfigure}
				\begin{subfigure}[t]{0.3\textwidth}
					\center
					\input{figures/ringNetworkB02}
					\caption{Watts-Strogatz ($\beta = 0.2$)}
					\label{fig:ringNetworkB02}
				\end{subfigure}
				\begin{subfigure}[t]{0.3\textwidth}
					\center
					\input{figures/ringNetworkB1}
					\caption{Random ($\beta = 1.0$)}
					\label{fig:ringNetworkB1}
				\end{subfigure}
				
				\caption{Watts-Strogatz networks with a range of rewiring
				probabilities.}
				\label{fig:ringNetwork}
			\end{figure}
		
		\subsection{Modelling and results}
			
			% Don't need too many links to get a good return in terms of reduced
			% path length. Limiting results to short wires doesn't hurt too much,
			% especially after folding.
			
			\begin{figure}
				\center
				\begin{subfigure}[t]{0.45\textwidth}
					\center
					\input{figures/torusNetwork}
					\caption{Unmodified torus ($\beta=0.0$)}
					\label{fig:torusNetworkB0}
				\end{subfigure}
				\begin{subfigure}[t]{0.45\textwidth}
					\center
					\input{figures/torusNetworkB01}
					\caption{Rewired torus ($\beta=0.1$)}
					\label{fig:torusNetworkB01}
				\end{subfigure}
				
				\caption{Extension of the Watts-Strogatz model to a 6-ary 2-cube.}
				\label{fig:torusNetwork}
			\end{figure}
			
			\begin{figure}
				\center
				\includegraphics[width=0.7\textwidth]{figures/smallWorldTorus}
				\caption[Average shortest-path length for folded 40-ary 2-cube.]{Average
				shortest-path length for folded 40-ary 2-cube (mean of 10 runs, error
				bars show 1 standard deviation).}
				\label{fig:smallWorldTorus}
			\end{figure}
			
			This algorithm is readily extended to torus topologies similar to
			SpiNNaker's. In this preliminary work, a $k$-ary 2-cube (a two dimensional
			torus $k$ nodes long in each dimension) was used as the initial network as
			in figure \ref{fig:torusNetworkB0}.  Random permutations are introduced as
			in the Watts-Strogatz model resulting in a network such as figure
			\ref{fig:torusNetworkB01}. A $k$-ary $n$-cube has an average shortest path
			length of $\frac{nk}{4}$.  This is because a packet travels (on average,
			under uniform random traffic) $\frac{1}{4}$ of the way around each of the
			$n$, $k$-node-long dimensions. In the figure, that means the average path
			length is $\frac{2 \times 6}{4} = 3$. Experiments using a simple
			graph-based model were carried out to determine the effects of rewiring on
			shortest-path length.  For the rewired network, the average shortest path
			is reduced from 3 to 2.77 hops.  Further, this model was used to confirm
			findings by Shin et al.  \cite{shin11} who found an increase in bandwidth
			when even just a small number of links are rewired. Figure
			\ref{fig:smallWorldTorus} demonstrates that this effect also applies to
			latency.
			
			\begin{figure}
				\center
				\includegraphics[width=0.7\textwidth]{figures/smallWorldLimitedWiring}
				\caption{Average shortest-path length for folded 40-ary 2-cube with 1\%
				rewiring}
				\label{fig:smallWorldLimitedWiring}
			\end{figure}
			
			Unfortunately, random links can be physically very long which, as
			described in the previous section, can cause problems for electrical
			high-speed serial links.  Though techniques exist to attempt to optimise
			the lay-out of networks containing random wiring \cite{koibuchi13}, these
			do not deal well with networks which also feature a large degree of
			regularity. An alternative approach is to simply limit the length of wires
			randomly inserted.  Unfortunately this fails to yield large reductions in
			path length in systems laid out na\"ively as in figure
			\ref{fig:torusNetwork}. If the network is folded as described in the
			previous section, however, significant reductions can be achieved. Figure
			\ref{fig:smallWorldLimitedWiring} shows the effect of rewiring 1\% of
			links when the maximum length of a randomly inserted wire is limited.  For
			networks folded twice (as in the case of the proposed SpiNNaker wiring
			plan), limiting wire length has little impact.
		
		\subsection{Further work}
			
			Figure \ref{fig:ringNetworkLimitedWires} shows valid random links in a
			small ring network if it were folded and random wires were limited to only
			short lengths. Nodes near the top and bottom of the ring potentially have
			shorter average path lengths compared with other nodes than nodes near the
			left and right of the ring. This is because the allowed links for top and
			bottom nodes connect nodes greater logical distances apart in the ring
			than those allowed on the left and right. The result is that the average
			path length from two different nodes becomes non-uniform across nodes in
			different parts of the system.
			
			\begin{figure}
				\center
				\input{figures/ringNetworkLimitedWires}
				\caption[Valid random links in a folded ring network with short
				wires.]{Valid random links in ring network when folded and added wires
				limited to a length of 1 unit.}
				\label{fig:ringNetworkLimitedWires}
			\end{figure}
			
			The effect of this non-uniformity is yet to be studied. In particular, the
			magnitude of the differences between average path lengths in different
			parts of a network is reduced both in higher dimensional topologies and
			also after the network has been folded and mapped into physical racks and
			cabinets. Future work intends to implement a small-world style network
			both within the simulator described in the next section and, subsequently,
			within SpiNNaker's board-to-board links.
	
	
	\section{SpiNNaker network modelling}
		
		% Colaboration with others researching simulator platforms, due for journal
		% submission in coming months, final stages of writing. Context of the work:
		% want to try out modelling on different platforms. My contribution: some
		% writing and the development of an accurate software simulator for
		% SpiNNaker's interconnect. This work indirectly offers interesting insights
		% into behaviour due to the board-to-board links.
		
		A recent collaboration with other researchers within the school has
		investigated novel methods for high-level simulation and modelling of large
		scale systems. This work used SpiNNaker's interconnection network as its
		case study and included the development of a number of different simulators
		including both software and FPGA-based models. The work revealed that modern
		high-level languages for FPGA and hardware development, such as Bluespec
		System Verilog (BSV) \cite{nikhil04}, have reached a level of development
		efficiency comparable with software. This result demonstrates that modellers
		are no-longer faced with a decision of whether time allows for a hardware
		model but rather whether advantages of FPGA-based models, such as
		substantial simulation speed improvements, are desired over software based
		approaches.  The work is in its final draft and planned for journal
		submission in August this year.
		
		The author's primary contribution to this work has centred around the
		development of a detailed software model of SpiNNaker's interconnection
		network. In addition, a significant portion of the analysis of the
		simulators was also carried out. In this section, the simulator, named
		`Tickysim', is described below along with brief summary of results
		demonstrating faithfulness to the system it models. The section concludes
		with plans to use this simulator to guide future research.
		
		\subsection{Software simulator model}
			
			% Model 18 cores as traffic generators/consumers. Links are modelled as
			% delay elements (accurately captures req/ack links), internal arbitration
			% scheme is modelled along with pipelined router.
			
			\begin{figure}
				\begin{subfigure}[b]{0.65\textwidth}
					\center
					\tikzexternaldisable
					\input{figures/tickysim-model}
					\caption{Model of a SpiNNaker chip. A packet generator and consumer
					model SpiNNaker's eighteen cores. A tree of packet arbiters mimicking
					SpiNNaker's Network on Chip (NoC) feeds a stream of packets into a
					router model.}
					\label{fig:tickysim-model-chip}
				\end{subfigure}
				~~~~~
				\begin{subfigure}[b]{0.28\textwidth}
					\centering
					\input{figures/link-delays}
					\vspace{1.8cm}
					
					\caption{Delay elements inserted between chips model the effects of
					link latency.}
					\label{fig:tickysim-model-link-delays}
				\end{subfigure}
				
				\caption{The Tickysim simulator model.}
				\label{fig:tickysim-model}
			\end{figure}
			
			The basic unit of the Tickysim simulator model is a high-level model of a
			single SpiNNaker chip which is summarised in figure
			\ref{fig:tickysim-model-chip}. Since the model focuses on the
			interconnection network, the eighteen processors on a SpiNNaker chip are
			modelled by a simple packet generator and consumer. This simplification
			saves much simulation overhead at the expense of detail in processor
			behaviour. Since the exact computation performed is not the focus of the
			model, this simplification should significantly impact results.
			
			The model captures the basic structure of the Network-on-Chip (NoC) within
			SpiNNaker chips. In particular, streams of packets incident on the chip
			are merged two-at-a-time in a tree structure before entering a model of
			the on-chip router. The simulated router models a multiple stage pipeline
			matching that of the SpiNNaker router along with packet dropping and other
			behaviours.
			
			The complete model consists of a network of these chip models
			interconnected by delay elements as illustrated in figure
			\ref{fig:tickysim-model-link-delays}.  These delay elements model the
			latency introduced when packets cross a chip-to-chip boundary.
			
			The model is extensively instrumented and configurable to allow a range of
			metrics to be collected and numerous parameters such as buffer sizes,
			injected traffic patterns and router behaviour to be modified. In
			addition, the software architecture is structured to allow straightforward
			extension making it suitable for use in later work.
			
			When configured to model a 144-chip SpiNNaker system, the model runs
			around 7,000 times slower than realtime on an Intel Xeon E3-1225 V2
			running at 3.2 GHz with 32 GB of RAM, the same order of magnitude
			slow-down experienced by comparable software simulators such as INSEE
			\cite{navaridas11insee}. Though the model itself is single threaded,
			parameter-sweep style experiments may be performed in parallel using
			commodity compute resources. Experiments conducted using idle workstations
			allowed hundreds of parameter settings to be tested in the time required
			to run a single experiment on a single machine.
		
		\subsection{Results}
			
			% Experiments performed showed highly matched behaviour between the model
			% and SpiNNaker but reveal the effects of the non-homogeneity introduced
			% by board-to-board links for certain traffic patterns.
			
			Experiments were carried out to verify that the simulators bore a close
			resemblance to the actual SpiNNaker hardware. These consisted of injecting
			a selection of synthetic traffic patterns at various injection rates and
			monitoring standard metrics such as number of packets dropped and accepted
			load (number of packets arriving at their destination).
			
			\begin{figure}
				\begin{subfigure}{\textwidth}
					\input{figures/plots}
					\plotresults{144}{cyclic}
					
					\caption{`Uniform' traffic.}
					\label{fig:results-144-accuracy-cyclic}
				\end{subfigure}
				
				\vspace{1em}
				
				\begin{subfigure}{\textwidth}
					\input{figures/plots}
					\plotresults{144}{complement}
					
					\caption{`Complement' traffic.}
					\label{fig:results-144-accuracy-complement}
				\end{subfigure}
				
				\caption[Packet acceptance and dropping in SpiNNaker
				and TIckysim.]{Comparison of accepted load and dropping rates in
				SpiNNaker and Tickysim. A load of 1.0 is equal to the bandwidth
				available across a single link. Packet dropping rates are as a
				proportion of the number of packets injected.}
				\label{fig:results-144-accuracy}
			\end{figure}
			
			Figure \ref{fig:results-144-accuracy-cyclic} gives a representative
			example of the results obtained. In this example, a `uniform' traffic
			pattern was used where nodes produce traffic destined for each node in the
			system in turn. Both SpiNNaker and the Tickysim model exhibit classic
			behaviour for this pattern with all traffic being accepted until a point
			when the network saturates.  Beyond this saturation point, packets are
			dropped. Since packets are dropped after a fixed timeout, this increases
			the time between sending of packets and thus causes the accepted load to
			drop to far below the rate immediately prior to saturation.
			
			\begin{figure}
				\center
				\input{figures/spinnaker-heatmaps}
				\caption[Packet dropping in a three board SpiNNaker machine.]{Packet
				dropping in a three board SpiNNaker machine under complement traffic at
				various injection rates. Thick lines show boundaries between boards in
				the system.}
				\label{fig:heatmap-spinnaker-complement}
			\end{figure}
			
			Some traffic patterns such as `complement', however, exhibited artefacts
			in SpiNNaker due to the prototype implementation of the HSS links between
			boards not being able to achieve full bandwidth. Since the difference due
			to these links is not modelled by Tickysim, their results clearly differ.
			Figure \ref{fig:results-144-accuracy-complement} demonstrates this effect
			in the form of two distinct phases of saturation in SpiNNaker but just one
			in Tickysim. With complement traffic, several distinct clusters of
			communicating nodes occur in the network. In SpiNNaker, those clusters
			which span board boundaries saturate first due to their lower bandwidth
			followed later by the native chip-to-chip links. This behaviour can be
			seen in \ref{fig:heatmap-spinnaker-complement} where there is a phase of
			packets being dropped in only certain parts of the network (a sign of
			saturation in those areas).
		
		\subsection{Further work}
			
			% Plans to include models of SpiNNaker links. Preliminary trials at
			% accurately modelling these have been unsuccessful. Will be used to guide
			% work on these links.
			
			Work is planned to model the behaviour of SpiNNaker's board-to-board links
			within Tickysim to allow its use in evaluating the utility of small world
			connectivity. Preliminary attempts to model board-to-board links as
			otherwise normal links but with longer latencies have been unsuccessful.
			It is suspected that the mechanisms used within the HSS links must also be
			modelled to match SpiNNaker's behaviour.
	
	
	\section{SpiNNaker FPGA connectivity}
		
		% Work started at CapoCaccia with input from various parties to get
		% SpiNNaker peripherals working. The start of a project to get peripherals
		% properly integrated and generally add some routing smarts to the FPGAs
		
		At the 2014 Capo Caccia Neuromorphic Workshop a group was formed to discuss
		requirements for extending the HSS links available within SpiNNaker for
		connecting peripherals and to host computers. In particular, the group was
		interested in the acceleration of the loading of neural models and
		extraction of results.  As a result of these discussions, work began to
		extend the existing infrastructure used for board-to-board links to support
		flexible additional connectivity. This work has concentrated on the
		development of FPGA designs to support tasks such as routing packets to and
		from peripherals and hosts and the integration of HSS links operating at
		different speeds.
		
		This section outlines the existing infrastructure for board-to-board links
		followed by a description of the extensions developed and how they address
		the requirements proposed at the workshop. The section concludes with
		planned future work which builds on the infrastructure developed.
		
			\subsection{Existing infrastructure}
				
				% Description of what exists already in the board-to-board links,
				% outline the protocol's principles. Also describe the rdy/vld
				% interface.
				
				\begin{figure}
					\center
					\input{figures/existing-fpga-links}
					
					\caption[Existing board-to-board link FPGA design.]{Existing
					board-to-board link FPGA design. Each FPGA contains two independent
					copies of this design so that the three FPGAs on each board can
					implement all six board-to-board links.}
					\label{fig:existing-fpga-links}
				\end{figure}
				
				The existing board-to-board links are implemented within the FPGAs on
				each SpiNNaker board (described previously in
				\S\ref{sec:spinnaker-fpgas} and figure \ref{fig:board-to-board-links}).
				Each HSS link is designed to carry eight chip-to-chip SpiNNaker links.
				The design, as shown in figure \ref{fig:existing-fpga-links} contains
				three basic elements. A `2-of-7' block translates between the
				asynchronous 2-of-7 protocol used by SpiNNaker chip links and the
				synchronous protocol used within the FPGA design. The next block
				assembles and disassembles `frames' containing SpiNNaker packets and
				ensures reliable communication by verifying incoming frames and
				retransmitting frames if required. The final block is provided as `hard
				IP' by the FPGA manufacturer rather than soft programmable FPGA logic
				enabling it to run at the high speeds used by HSS links.
				
			\subsection{Proof-of-concept I/O device}
				
				% Describe principle of how a router will be integrated and streams
				% merged.
				
				To enable extension of the existing board-to-board system for other
				purposes, the ready/valid protocol described previously, has been
				standardised for communication between new blocks. Additionally the
				standard dictates that the bus should be able to carry a complete 72-bit
				SpiNNaker packet each cycle.
				
				\begin{figure}
					\center
					\input{figures/proof-of-concept-fpga-links}
					
					\caption[Proof-of-concept low-speed I/O system.]{Proof-of-concept
					low-speed I/O system. A spare HSS link from an FPGA on a SpiNNaker
					board connects to an FPGA board connected to a host PC.}
					\label{fig:proof-of-concept-fpga-links}
				\end{figure}
				
				Based on the ready/valid standard, a number of basic components, such as
				simple routers, for extending the existing design were produced. Using
				these components, a simple proof of concept low-speed host connection
				was developed to allow injection and extraction of packets directly into
				the network. In this system, which is sketched in figure
				\ref{fig:proof-of-concept-fpga-links}, a SpiNNaker board is connected to
				an off-the-shelf FPGA development board
				\cite{raggedstone2} using an unused S-ATA connector on the SpiNNaker
				board. A host PC then connects to the FPGA board via an onboard FTDI
				USB-to-UART (Universal Asynchronous Receiver/Transmitter) converter
				providing a simple to drive but low speed (2.3 Mbit/s) compared to the
				HSS link (1.5 Gbits/s) connection over which SpiNNaker packets can be
				transmitted to and from the host.
				
				A router is used on the SpiNNaker boards' FPGAs to route packets from
				incoming SpiNNaker chips either along their usual board-to-board
				connection, to the FPGA board or both.  Packets are routed using the
				same key and mask mechanism described in \S\ref{sec:spinn-router} though
				in the current, preliminary design the routing table contains only a
				single entry.  Packets routed to the FPGA board the same HSS link
				protocol as board-to-board links to travel to and from the FPGA board.
				On the FPGA, one of the eight streams of packets is fed to a UART block
				which uses a simple protocol to send and receive SpiNNaker packets at
				low speed to a host PC. The UART connection to the host is the
				bottleneck in the system and more performant technologies such as USB
				3.0 would instantly enable greater performance. With this bottleneck
				removed the only overhead is an additional 13 ns of latency added by the
				router and throughput would be unaffected.
				
				This proof-of-concept device has been successfully integrated into the
				SpiNNaker implementation of Nengo where it can be used to transmit
				values in to and out of a model in realtime. Despite its low bandwidth,
				the link only transmits raw SpiNNaker packets and thus performs
				favourably compared to the previous Ethernet implementation whose
				protocol overheads resulted in low bandwidth.
			
			\subsection{Further work}
				
				% Next steps will involve getting basic routing up and running, then on
				% to my planned project, see next chapter.
				
				With the basic infrastructure in place for implementing custom routing
				schemes and using additional HSS links within SpiNNaker's FPGAs in
				place, it is now possible to develop high speed peripheral and host
				connectivity. In addition, this infrastructure allows for the addition
				of auxiliary links between boards which could be used for the
				implementation of small-world network connectivity.
				
				In collaboration with researchers at the Technical University of Munich,
				a small board containing an FPGA with both a HSS link and a USB 3.0 link
				is being developed. This board's FPGA could be loaded with a design very
				similar to that used in the existing FPGA board but with the UART block
				replaced with a USB 3.0 block. Using this board, high bandwidth
				communication between a host and SpiNNaker machine should become
				possible. As well as improving system performance this will also enable
				greater visibility of SpiNNaker's network behaviour which may prove
				valuable in later work.

